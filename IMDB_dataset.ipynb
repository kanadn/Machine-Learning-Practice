{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanadn/Machine-Learning-Practice/blob/master/IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfphsdRv2KWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlhQgDLBA5Uc",
        "colab_type": "code",
        "outputId": "75d39175-e4ee-41d4-ca6f-da06ee7e8f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "#(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIhRgxaJ7tCB",
        "colab_type": "text"
      },
      "source": [
        "IMDB dataset imported. My name is Kanad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WSTyBHxiYDi",
        "colab_type": "code",
        "outputId": "124dd087-01a5-408a-9552-54edd2bd1e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in test_data[15]])\n",
        "decoded_review"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? let me first start out by saying 1 out of 10 is too good for this movie it's unfortunate that imdb doesn't have ? of a star i watched this abortion of a movie in the middle of the night due to insomnia and it was absolute garbage the plot was horrible the acting was horrible the movie was utterly boring looked like the shadow with alec baldwin the shadow is infinitely better than this as well the character eve was so undeveloped and 2 dimensional she didn't even grab my attention i didn't even know her name was eve don was interesting when he kept his mouth shut the twist if you can call it that was laughable and pathetic when it came the movie had done such a horrid job of building suspense or ? to any character that i simply thought who gives a s the only thing that made me even lift an ? about this movie was the fact the ? teacher was ? in terminator 2 also a movie that was light years ahead of this motion picture massacre anyone who was involved in this movie should be ashamed of themselves for wasting 90 minutes of countless people's time it's no wonder no actor from this movie ever had a ? career in summary this movie is so bad i feel dirty and need a shower worst movie in history ? was better prom night the remake was better and dare i say it saw iv was better\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d51PQbQ8J5N",
        "colab_type": "text"
      },
      "source": [
        "Encoding integer sequence into binary matrix..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya-1A2ZG8rUz",
        "colab_type": "code",
        "outputId": "698a762c-8b64-4591-f05a-00f0349fe9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1\n",
        "  return results\n",
        "  \n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "print(x_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 1. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMqnFcg8ChND",
        "colab_type": "text"
      },
      "source": [
        "See working of enumerate() below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_806BEi__bc",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "4b0a00dd-2f36-460d-a9c6-20ec65fe6387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sequences=['a','b','c','d']\n",
        "for i, sequence in enumerate(sequences):\n",
        "  print('i=',i,'seq=',sequence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i= 0 seq= a\n",
            "i= 1 seq= b\n",
            "i= 2 seq= c\n",
            "i= 3 seq= d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncYogGwwbEvt",
        "colab_type": "text"
      },
      "source": [
        "Vectorize lables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiL6EhuGdH-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxyv_Jjf3rE4",
        "colab_type": "text"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eQeYDZk3uTp",
        "colab_type": "code",
        "outputId": "b835bb92-f42b-4f20-d0e4-b3c99d584c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 14:39:44.322665 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0701 14:39:44.360780 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0701 14:39:44.367716 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIdpmMPJ1i8H",
        "colab_type": "text"
      },
      "source": [
        "Compile the model. Choose loss function and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Fp_6j219Xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ae9aeae8-b978-4693-f752-78f319645253"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0701 14:39:50.548640 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0701 14:39:50.573138 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0701 14:39:50.579723 140079447099264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVJF7CadEFZB",
        "colab_type": "text"
      },
      "source": [
        "Setting aside a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrsKMywlEKMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA0JdWKSEcpM",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSYLAqb5EfpW",
        "colab_type": "code",
        "outputId": "b56dc801-3fe4-4da4-d100-48d96d19adfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0701 14:40:16.807327 140079447099264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 5s 348us/step - loss: 0.5084 - acc: 0.7813 - val_loss: 0.3797 - val_acc: 0.8684\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.3004 - acc: 0.9047 - val_loss: 0.3004 - val_acc: 0.8897\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.2179 - acc: 0.9285 - val_loss: 0.3085 - val_acc: 0.8711\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.2840 - val_acc: 0.8832\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2841 - val_acc: 0.8872\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.1150 - acc: 0.9650 - val_loss: 0.3166 - val_acc: 0.8772\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.3127 - val_acc: 0.8846\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.3859 - val_acc: 0.8649\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.3635 - val_acc: 0.8782\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0561 - acc: 0.9853 - val_loss: 0.3843 - val_acc: 0.8792\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0439 - acc: 0.9893 - val_loss: 0.4153 - val_acc: 0.8779\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0381 - acc: 0.9921 - val_loss: 0.4525 - val_acc: 0.8690\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0300 - acc: 0.9928 - val_loss: 0.4698 - val_acc: 0.8729\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0247 - acc: 0.9945 - val_loss: 0.5022 - val_acc: 0.8726\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0175 - acc: 0.9979 - val_loss: 0.5341 - val_acc: 0.8693\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0149 - acc: 0.9983 - val_loss: 0.5709 - val_acc: 0.8697\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0151 - acc: 0.9971 - val_loss: 0.6024 - val_acc: 0.8697\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0075 - acc: 0.9996 - val_loss: 0.6782 - val_acc: 0.8633\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6693 - val_acc: 0.8674\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.6941 - val_acc: 0.8658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZssSqvnhFZ-p",
        "colab_type": "text"
      },
      "source": [
        "The model is trained now, let's use it for test data and check the results in terms of accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwRo3N5cGCjT",
        "colab_type": "code",
        "outputId": "6871d8b5-3585-4346-b5ff-ea6c2ee08d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 2s 78us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jf3ndwqvPKO",
        "colab_type": "code",
        "outputId": "3ff501e8-eb6b-4240-f6d5-5dec55e2000c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"{0:.2f}\".format(100*acc))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMHL_ZwMHQ86",
        "colab_type": "text"
      },
      "source": [
        "That means 85.23% accuracy!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEph4YK1YGQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSYv1lSbYZuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions[69]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}